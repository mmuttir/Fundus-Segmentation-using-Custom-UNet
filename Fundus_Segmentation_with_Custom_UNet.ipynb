{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1hBV8O50XU4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '../dataset/DRIVE/images'\n",
        "mask_path = '../dataset/DRIVE/mask'\n",
        "image_size = (256, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data(dataset_path, mask_path):\n",
        "    images = []\n",
        "    masks = []\n",
        "    \n",
        "    for img_name in os.listdir(dataset_path):\n",
        "        img = cv2.imread(os.path.join(dataset_path, img_name))\n",
        "        img = cv2.resize(img, image_size)\n",
        "        images.append(img)\n",
        "\n",
        "        mask_name = img_name.replace(\".tif\", \"_mask.gif\")\n",
        "        mask = cv2.imread(os.path.join(mask_path, mask_name), cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, image_size)\n",
        "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "images, masks = load_data(dataset_path, mask_path)\n",
        "images = images.astype('float32') / 255.0\n",
        "masks = masks.astype('float32') / 255.0\n",
        "masks = np.expand_dims(masks, axis=-1)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "iTaOHbgx0t0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(num_filters, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def custom_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = conv_block(inputs, 32)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(0.1)(p1)\n",
        "\n",
        "    c2 = conv_block(p1, 64)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(0.1)(p2)\n",
        "\n",
        "    c3 = conv_block(p2, 128)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(0.1)(p3)\n",
        "\n",
        "    c4 = conv_block(p3, 256)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(0.1)(p4)\n",
        "\n",
        "    # Bridge\n",
        "    c5 = conv_block(p4, 512)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(0.1)(u6)\n",
        "    c6 = conv_block(u6, 256)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(0.1)(u7)\n",
        "    c7 = conv_block(u7, 128)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(0.1)(u8)\n",
        "    c8 = conv_block(u8, 64)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(0.1)(u9)\n",
        "    c9 = conv_block(u9, 32)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[outputs])\n"
      ],
      "metadata": {
        "id": "eti4SAnm1Fy5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build the model\n",
        "input_shape = (image_size[0], image_size[1], 3)\n",
        "model = custom_unet(input_shape)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "n7jWX-XP1JHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Define the Dice Loss function\n",
        "def dice_loss(y_true, y_pred):\n",
        "    numerator = 2 * K.sum(y_true * y_pred, axis=(1,2,3))\n",
        "    denominator = K.sum(y_true + y_pred, axis=(1,2,3))\n",
        "    return 1 - (numerator + 1) / (denominator + 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "CFhNVMGr-BRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "# Compile the model using the Dice Loss function\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=dice_loss, metrics=['accuracy'])\n",
        "\n",
        "# Define data augmentation\n",
        "data_gen_args = dict(rotation_range=20,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     horizontal_flip=True,\n",
        "                     fill_mode='nearest')\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "image_datagen.fit(X_train, augment=True, seed=42)\n",
        "mask_datagen.fit(y_train, augment=True, seed=42)\n",
        "\n",
        "image_generator = image_datagen.flow(X_train, batch_size=8, seed=42)\n",
        "mask_generator = mask_datagen.flow(y_train, batch_size=8, seed=42)\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "DfFq5NJ_1cJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(X_train) // 8,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[checkpoint, reduce_lr, early_stopping])"
      ],
      "metadata": {
        "id": "lXOArEDG1kXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best saved model\n",
        "best_model = load_model('best_model.h5')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "# Threshold predictions\n",
        "y_pred_thresholded = (y_pred > 0.5).astype(np.uint8)\n",
        "\n",
        "# Function to display images and masks\n",
        "def display_images(images, masks, predictions, num_images=5):\n",
        "    fig, axs = plt.subplots(num_images, 3, figsize=(12, num_images * 4))\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        axs[i, 0].imshow(images[i])\n",
        "        axs[i, 0].set_title('Original Image')\n",
        "        axs[i, 1].imshow(masks[i, :, :, 0], cmap='gray')\n",
        "        axs[i, 1].set_title('Ground Truth Mask')\n",
        "        axs[i, 2].imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "        axs[i, 2].set_title('Predicted Mask')\n",
        "        \n",
        "        for j in range(3):\n",
        "            axs[i, j].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display images, ground truth masks, and predicted masks\n",
        "display_images(X_val, y_val, y_pred_thresholded)\n"
      ],
      "metadata": {
        "id": "_WjyIJuM2an5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import jaccard_score, f1_score, precision_score, recall_score\n",
        "import itertools\n",
        "from scipy import ndimage\n",
        "\n",
        "# Flatten the ground truth masks and predicted masks for metric calculation\n",
        "y_val_flat = y_val.flatten()\n",
        "y_pred_thresholded_flat = y_pred_thresholded.flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "iou = jaccard_score(y_val_flat, y_pred_thresholded_flat)\n",
        "dice = f1_score(y_val_flat, y_pred_thresholded_flat)\n",
        "precision = precision_score(y_val_flat, y_pred_thresholded_flat)\n",
        "recall = recall_score(y_val_flat, y_pred_thresholded_flat)\n",
        "\n",
        "print(f\"IoU: {iou:.4f}\")\n",
        "print(f\"Dice Coefficient: {dice:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Post-processing: Morphological opening\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "y_pred_postprocessed = [ndimage.binary_opening(pred[0], structure=kernel).astype(np.uint8) for pred in y_pred_thresholded]\n",
        "\n",
        "# Visualize the post-processed results\n",
        "display_images(X_val, y_val, y_pred_postprocessed, num_images=5)\n"
      ],
      "metadata": {
        "id": "hw2J-52e9sdX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}